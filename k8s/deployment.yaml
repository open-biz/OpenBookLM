apiVersion: apps/v1
kind: Deployment
metadata:
  name: openbooklm
  namespace: openbooklm
  labels:
    app: openbooklm
spec:
  replicas: 1
  selector:
    matchLabels:
      app: openbooklm
  template:
    metadata:
      labels:
        app: openbooklm
    spec:
      containers:
        # Frontend container
        - name: frontend
          image: node:20-slim
          ports:
            - containerPort: 3000
          env:
            - name: NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY
              valueFrom:
                secretKeyRef:
                  name: clerk-credentials
                  key: NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY
            - name: CLERK_SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: clerk-credentials
                  key: CLERK_SECRET_KEY
            - name: DATABASE_URL
              valueFrom:
                secretKeyRef:
                  name: db-credentials
                  key: DATABASE_URL
            - name: REDIS_URL
              valueFrom:
                secretKeyRef:
                  name: redis-credentials
                  key: REDIS_URL
            - name: NODE_ENV
              value: 'production'
            - name: NEXT_PUBLIC_API_URL
              valueFrom:
                configMapKeyRef:
                  name: openbooklm-config
                  key: API_URL
            - name: NEXT_PUBLIC_BASE_URL
              valueFrom:
                configMapKeyRef:
                  name: openbooklm-config
                  key: BASE_URL
            # Add Cerebras API key to frontend
            - name: CEREBRAS_API_KEY
              valueFrom:
                secretKeyRef:
                  name: api-credentials
                  key: CEREBRAS_API_KEY
            # Google API credentials
            - name: NEXT_PUBLIC_GOOGLE_CLIENT_ID
              valueFrom:
                secretKeyRef:
                  name: google-credentials
                  key: NEXT_PUBLIC_GOOGLE_CLIENT_ID
            - name: GOOGLE_CLIENT_SECRET
              valueFrom:
                secretKeyRef:
                  name: google-credentials
                  key: GOOGLE_CLIENT_SECRET
            - name: NEXT_PUBLIC_GOOGLE_API_KEY
              valueFrom:
                secretKeyRef:
                  name: google-credentials
                  key: NEXT_PUBLIC_GOOGLE_API_KEY
          resources:
            requests:
              cpu: '500m'
              memory: '1Gi'
            limits:
              cpu: '1000m'
              memory: '2Gi'
          command: ['/bin/sh', '-c']
          args:
            - |
              set -e
              apt-get update
              apt-get install -y git openssl libssl-dev ca-certificates
              npm install -g pnpm
              git clone -b feat/connor/tmp-host https://github.com/open-biz/openbooklm.git
              cd openbooklm
              pnpm install
              npx prisma generate
              pnpm build
              pnpm start
        # Backend container (single definition)
        - name: backend
          image: python:3.12-slim
          ports:
            - containerPort: 8000
          env:
            - name: CEREBRAS_API_KEY
              valueFrom:
                secretKeyRef:
                  name: api-credentials
                  key: CEREBRAS_API_KEY
            - name: LLAMA_API_KEY
              valueFrom:
                secretKeyRef:
                  name: api-credentials
                  key: LLAMA_API_KEY
            - name: OPENAI_API_KEY
              valueFrom:
                secretKeyRef:
                  name: api-credentials
                  key: OPENAI_API_KEY
          # Backend container
          command: ['/bin/sh', '-c']
          args:
            - |
              set -e
              apt-get update
              apt-get install -y git python3-pip python3-venv ffmpeg libsndfile1 libportaudio2
              git clone -b feat/connor/tmp-host https://github.com/open-biz/openbooklm.git
              cd openbooklm
              chmod +x setup/create_venv.sh
              # Install packages in smaller groups to manage memory better
              python3 -m venv venv
              . venv/bin/activate
              pip install --no-cache-dir -U pip setuptools wheel
              # Install core dependencies first
              pip install --no-cache-dir torch transformers scipy numpy
              # Install remaining packages
              pip install --no-cache-dir -r requirements.txt
              # Run the Groq server
              python3 backend/groq/main.py
          resources:
            requests:
              cpu: '500m'
              memory: '8Gi' # Increased from 4Gi
            limits:
              cpu: '1000m'
              memory: '16Gi' # Increased from 8Gi
          # Removed readinessProbe and livenessProbe
